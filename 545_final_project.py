# -*- coding: utf-8 -*-
"""Copy of 545 FINAL Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cR43U1m0ogvI-NK19L7o-N4Y2y8L7u9U

# Climate Change

By: Ryan Boyle, Caleb Gupta, and Christa Simaan

# Introduction

Inside this notebook, we will be using a staff proposed data set, Earth Surface Temperature Data, as well as two additional csv files on boh greenhouse gases and natural disaster rates in order to analyze information about the varying surface temperatures on Earth! (and many of the possible consequences of such actions).

This project is rather interesting because climate change has been more and more of an increasing issue. We are excited to show you how it has and will affect countries, major cities, and states. This deck is best used in the context of current events (specifically political actions towards climate), where one can observe the specific temperatures and natural disasters of regions that chose specific actions. Of course, due to geographical proximity, even this must be interpretted fully in context. 

We take several actions in order to organize this data into interpretable chunks. The overall structure is as follows:

*   Data Wrangling of the State, City, and Country tables
*   Exploratory Data Analysis and Visualization of the Average Temperatures
* Using Machine Learning to Make Temperature Predictions
* Conncection to Natural Disasters

We use different techniques and figures to represent the interconnection and correlations between these surface temperatures with various possible attrocities so that we can see for ourselves the trends. This is a topic that often has misinformation and we have seen through working with the data that there are many exceptions from the overall trends that can be cherry picked in order to demonstrate certain narratives. We aim that this presentation is able to be a wholistic and accurate representation of the data.

The timeline in which we predict most of our models span until 2050 and with major legislation planned to take full effect a full decade before this we found that any further predictions would not reflect the state of the world accurately. We hope you enjoy the cool, groundbreaking results from this dataset and can potentially re-observe them in 2050 to see if the temperature predictions held true.

# Section 0: Libraries and Set Up
"""

# Versioning again
!pip install pandas==1.1.5

# Sklearn and Pandas Setup
import json
import glob
import pandas as pd
import numpy as np
import datetime as dt
import re
import os
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from matplotlib import cm
from google.colab import drive

!apt update
!apt install gcc python-dev libkrb5-dev

!nvidia-smi

! pip install lightning-python

"""# Section 1: Data Wrangling and Cleaning

**Reading in the data from CSV files**


---

Here, we read in the CSVs for Major Cities, Countries, and States in order to get them into their own respective dataframe. We used data from Kaggle, which can be found [here](https://www.kaggle.com/datasets/berkeleyearth/climate-change-earth-surface-temperature-data).
"""

cities_df = pd.read_csv('GlobalLandTemperaturesByMajorCity.csv')

countries_df = pd.read_csv('GlobalLandTemperaturesByCountry.csv')

states_df = pd.read_csv('GlobalLandTemperaturesByState.csv')

"""**Cleaning the data**


---


For each dataframe, we will:

*   Drop all rows with null values
*   Rename the 'dt' column to 'Date'
*   Make 'Year', 'Month', and 'Day' columns using the 'Date' column
*   Change the 'Year' column to be of type int64

Below, we drop the NA cells in each of the dataframes we created.
"""

#drop NA
cities_df = cities_df.dropna()
countries_df = countries_df.dropna()
states_df = states_df.dropna()

"""Below, we rename the dt column in each of the dataframes we created to be Date."""

#Rename dt to Date
cities_df = cities_df.rename(columns={'dt' : 'Date'})
countries_df = countries_df.rename(columns={'dt' : 'Date'})
states_df = states_df.rename(columns={'dt' : 'Date'})

"""Below, we split up the Date column into a Year, Month, and Day column so that we can group in terms of year and analyze the data over the years."""

# Make year, month, and date column for each df
cities_df[['Year', 'Month', 'Day']] = cities_df.Date.str.split('-', expand=True)
countries_df[['Year', 'Month', 'Day']] = countries_df.Date.str.split('-', expand=True)
states_df[['Year', 'Month', 'Day']] = states_df.Date.str.split('-', expand=True)

"""Below, we save a copy of the original dataframes, and name them cities_monthly_df, countries_monthly_df, and states_monthly_df. We also create dataframes cities_yearly_df, countries_yearly_df, and states_yearly_df, which store the yearly average temperature of every city, country, or state respectively. In each of cities_yearly_df, countries_yearly_df, and states_yearly_df, we drop the unnecassary columns. """

#Save the monthly data into seperate dataframes
cities_monthly_df = cities_df
countries_monthly_df = countries_df
states_monthly_df = states_df

# groupby the year
cities_yearly_df = cities_df.groupby(['City', 'Year']).mean().reset_index()
countries_yearly_df = countries_df.groupby(['Country', 'Year']).mean().reset_index()
states_yearly_df = states_df.groupby(['State', 'Year']).mean().reset_index()

"""Below, we will change the Date column of each dataframe to be of type int64."""

#Change the Year column to be of type int64
cities_monthly_df = cities_monthly_df.astype({"Year": 'int64'}, errors='raise') 
countries_monthly_df = countries_monthly_df.astype({"Year": 'int64'}, errors='raise') 
states_monthly_df = states_monthly_df.astype({"Year": 'int64'}, errors='raise')

cities_yearly_df = cities_yearly_df.astype({"Year": 'int64'}, errors='raise') 
countries_yearly_df = countries_yearly_df.astype({"Year": 'int64'}, errors='raise') 
states_yearly_df = states_yearly_df.astype({"Year": 'int64'}, errors='raise')

"""# Section 2: Exploratory Data Analysis and Visualization

**Familiarizing ourselves with the data**


---

Below, we used the .info() and .describe() functions to explore the characteristics of the data that we are working with to identify what aspects of the data we need to keep in mind as we continue with EDA. \
*Not all of this is shown in code below
"""

cities_monthly_df.info()

cities_monthly_df.describe()

cities_yearly_df.info()

cities_yearly_df.describe()

len(cities_monthly_df['City'].unique())

len(countries_monthly_df['Country'].unique())

"""Some things that we noticed: the data in the AverageTemperature column is in units of degrees Celcius, the dataset includes data starting at the year 1743 up until the year 2013, the cities dataset includes data for 100 different cities, and the countries dataset includes data for 242 different countries. Additionally, we noted that the original dataset includes the average temperature of each city, country, or state from every month of every year. However, since we dropped rows with null values, data from some months are missing in the monthly dataframes.

**Identifying the hottest and coldest cities**


---

First, we wanted to identify the 5 hottest cities and 5 coldest cities in the year 2013. We stored these in dataframes called hottest_5_cities_df and coldest_5_cities_df respectively.
"""

hottest_5_cities_df = cities_yearly_df[cities_yearly_df['Year'] == 2013].sort_values('AverageTemperature', ascending=False).head(5)
coldest_5_cities_df = cities_yearly_df[cities_yearly_df['Year'] == 2013].sort_values('AverageTemperature', ascending=True).head(5)

hottest_5_cities_df

coldest_5_cities_df

"""From this, we can see that Umm Durman (Omdurman), Madras, Bangkok, Jiddah, and Hyderabad were the 5 hottest cities in the year 2013, and Harbin, Santiago, Saint Petersburg, Moscow, and Changchun were the 5 coldest cities in the year 2013. Below, we use a barplot to visualize the 2013 average temperature of these 5 hottest and 5 coldest cities. """

hottest_coldest_cities_df = pd.concat([hottest_5_cities_df, coldest_5_cities_df]).sort_values('AverageTemperature', ascending=False)
sns.set(rc = {'figure.figsize':(15,10)})
hottest_coldest_barplot = sns.barplot(x = 'City', y = 'AverageTemperature', data = hottest_coldest_cities_df, palette = 'rocket')
hottest_coldest_barplot.set(title = 'Average Temperature of the Hottest and Coldest Cities in 2013')
hottest_coldest_barplot.set(xlabel = 'City', ylabel = 'Average Temperature in 2013')
hottest_coldest_barplot

"""**Visualizing temperature geographically in US states**


---

We then wanted to visualize the temperature of different geographic regions in a map to see how geographic location affects temperature. To do this, we used Lightning to visualize the average temperature in US states in the year 2013.
"""

from lightning import Lightning
from numpy import random

states = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 
          'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 
          'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 
          'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 
          'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']

US_states_monthly_df = states_monthly_df[states_monthly_df['Country'] == 'United States']
US_states_yearly_df = US_states_monthly_df.groupby(['State', 'Year']).mean().reset_index()
US_states_2013_df = US_states_yearly_df[(US_states_yearly_df['Year'] == 2013) & (US_states_yearly_df['State'] != 'District Of Columbia')]

values = list(US_states_2013_df['AverageTemperature'])
lgn = Lightning(ipython=True, local=True)
lgn.map(states, values, colormap = 'Greens')

"""In the map above, darker colors represent higher temperature. We can clearly see that temperatures increase as you go further south. That is, southern states in the US had a higher average temperature in 2013 than northern states. This makes sense and aligns with what we had expected because regions closer to the equator have higher temperatures.

**Visualizing seasonal trends in the data**


---

Since temperatures rise during the summer and fall during the winter, following a yearly cycle, we knew that if we were to plot the monthly data for any city, we would be able to see this seasonal trend. We decided to plot the monthly average temperature data from 1995 to 2000 for the city Umm Durman to visualize this yearly cycle.
"""

UmmDurman_monthly = cities_monthly_df[(cities_monthly_df['City'] == 'Umm Durman') & (cities_monthly_df['Year'] >= 1995) & (cities_monthly_df['Year'] <= 2000)]
UmmDurman_monthly = UmmDurman_monthly.set_index('Date')
sns.set(rc = {'figure.figsize': (15, 10)})
UmmDurman_monthly['AverageTemperature'].plot()

"""The average temperature in Umm Durman is around the same during the same month of each year. This is exactly what we would expect of this data because temperature changes depending on the season and follows a yearly cycle. We can deduce from the plot that the temperature in Umm Durman is highest during May and June, and the temperature is lowest in January and February.

If we were to plot the yearly average temperature for any city, we would not see these seasonal cycles. We would expect the yearly average temperature of any city to be somewhat consistent, potentially rising or falling due to climate change. Below, we use a boxplot to visualize the temperature distributions by year in Umm Durman from 1995 to 2000.
"""

UmmDurman_monthly = cities_monthly_df[(cities_monthly_df['City'] == 'Umm Durman') & (cities_monthly_df['Year'] >= 1995) & (cities_monthly_df['Year'] <= 2000)]
years = pd.DataFrame()
years['1995'] = pd.Series(list(UmmDurman_monthly[UmmDurman_monthly['Year'] == 1995]['AverageTemperature']), index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])
years['1996'] = pd.Series(list(UmmDurman_monthly[UmmDurman_monthly['Year'] == 1996]['AverageTemperature']), index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])
years['1997'] = pd.Series(list(UmmDurman_monthly[UmmDurman_monthly['Year'] == 1997]['AverageTemperature']), index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])
years['1998'] = pd.Series(list(UmmDurman_monthly[UmmDurman_monthly['Year'] == 1998]['AverageTemperature']), index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])
years['1999'] = pd.Series(list(UmmDurman_monthly[UmmDurman_monthly['Year'] == 1999]['AverageTemperature']), index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])
years['2000'] = pd.Series(list(UmmDurman_monthly[UmmDurman_monthly['Year'] == 2000]['AverageTemperature']), index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])
#years.boxplot()
UmmDurman_box_plot = sns.boxplot(data = years)
UmmDurman_box_plot.set(title = 'Temperature Distribution by Year in Umm Durman')
UmmDurman_box_plot.set(xlabel = 'Year', ylabel = 'Temperature Distribution')
UmmDurman_box_plot

"""In this boxplot the data looks stationary, meaning that there are no obvious trends or seasonality when we consider the yearly average temperature.

**Analyzing temperature change over time**


---

Due to global climate change, we expect that there has been a change in temperature over time. In particular, we think that global warming has caused temperatures to increase in many countries. Below, we plotted the monthly temperature in the US in the years 1900 and 2000 side-by-side.
"""

US_monthly_1900_df = countries_monthly_df[(countries_monthly_df['Country'] == 'United States') & (countries_monthly_df['Year'] == 1900)]
US_monthly_2000_df = countries_monthly_df[(countries_monthly_df['Country'] == 'United States') & (countries_monthly_df['Year'] == 2000)]
plt.plot(US_monthly_1900_df['Month'], US_monthly_1900_df['AverageTemperature'], color = 'r', label= '1900')
plt.plot(US_monthly_2000_df['Month'], US_monthly_2000_df['AverageTemperature'], color = 'b',label = '2000')
plt.legend()
plt.title('US Monthly Temperature in 1900 and 2000')
plt.xlabel('Month')
plt.ylabel('Temperature')
plt.show()

"""From this plot, we can clearly see that the US temperature during the months of January to September in 2000 was greater than the temperature during those months in 1900.

We then wanted to see if any cities, states, or countries have experienced a significant change in average yearly temperature between 1900 and 2000. We started with our cities data set.
"""

cities_1900_df = cities_yearly_df[cities_yearly_df['Year'] == 1900][['City', 'AverageTemperature']]
cities_1900_df = cities_1900_df.rename(columns={'AverageTemperature' : 'AvgTempIn1900'})

cities_2000_df = cities_yearly_df[cities_yearly_df['Year'] == 2000][['City', 'AverageTemperature']]
cities_2000_df = cities_2000_df.rename(columns={'AverageTemperature' : 'AvgTempIn2000'})

cities_1900_2000_df = pd.merge(cities_1900_df, cities_2000_df, how="inner", on=['City'])
cities_1900_2000_df['ChangeInAvgTemp'] = cities_1900_2000_df['AvgTempIn2000'] - cities_1900_2000_df['AvgTempIn1900']
cities_1900_2000_df = cities_1900_2000_df.sort_values('ChangeInAvgTemp', ascending=False).reset_index()
cities_1900_2000_df

cities_1900_2000_df.boxplot(column=['AvgTempIn1900', 'AvgTempIn2000'], grid=True)
plt.title('Cities Average Temperature 1900 vs 2000')

"""From this, we are able to see how the overall temperatures rose
for the cities in just a century, from 1900 to 2000.

We can also see from this dataframe that Saint Petersburg is the city with the greatest change in average temperature from 1900 to 2000. The graph below presents a visualization of the change in average temperature in saint petersburg from 1900 to 2000.
"""

import scipy as sp

cities_change_df = cities_yearly_df[(cities_yearly_df['Year'] >= 1900) & (cities_yearly_df['Year'] <= 2000)][['City', 'Year', 'AverageTemperature']]
cities_change_df = cities_change_df.sort_values('Year', ascending=True)
st_petersburg_change_df = cities_change_df[cities_change_df['City'] == 'Saint Petersburg']

sns.set(rc = {'figure.figsize':(15,10)})
cities_change_graph = sns.regplot(x = 'Year', y = 'AverageTemperature', data = st_petersburg_change_df)
cities_change_graph.set( xlabel = "Year", ylabel = "Average Temperature")
cities_change_graph.set(title="Yearly Average Temperature of Saint Petersburg from 1900 to 2000")
cities_change_graph

"""In the graph above, we can see that the line of best fit has a positive slope, demonstrating how the average temperature has increased over time. """

sns.set(rc = {'figure.figsize':(15,10)})
sns.scatterplot(data= cities_1900_2000_df, x="index", y="ChangeInAvgTemp")
plt.title('Change in average temperature for each city from 1900 to 2000')

"""We then wanted to count the number of cities that experienced an increase in average yearly temperature from 1900 to 2000, and the number of cities that experiences a decrease in average yearly temperature from 1900 to 2000. We stored these values in the variables count_less_cities and count_greater_cities respectively."""

count_less_cities = cities_1900_2000_df['ChangeInAvgTemp'][cities_1900_2000_df['ChangeInAvgTemp'] < 0.0].count()
count_greater_cities = cities_1900_2000_df['ChangeInAvgTemp'][cities_1900_2000_df['ChangeInAvgTemp'] > 0.0].count()

count_less_cities

count_greater_cities

"""From what we can see here, there are 89 cities that have a change in the average temperature that are greater than 0 and 11 cities that have a change in the average temperature that are below 0. That is a 89% rate for increasing temperatures overall in the cities from 1900 to 2000.

We then repeated this whole process with our countries data set.
"""

countries_1900_df = countries_yearly_df[countries_yearly_df['Year'] == 1900][['Country', 'AverageTemperature']]
countries_1900_df = countries_1900_df.rename(columns={'AverageTemperature' : 'AvgTempIn1900'})

countries_2000_df = countries_yearly_df[countries_yearly_df['Year'] == 2000][['Country', 'AverageTemperature']]
countries_2000_df = countries_2000_df.rename(columns={'AverageTemperature' : 'AvgTempIn2000'})

countries_1900_2000_df = pd.merge(countries_1900_df, countries_2000_df, how="inner", on=['Country'])
countries_1900_2000_df['ChangeInAvgTemp'] = countries_1900_2000_df['AvgTempIn2000'] - countries_1900_2000_df['AvgTempIn1900']
countries_1900_2000_df = countries_1900_2000_df.sort_values('ChangeInAvgTemp', ascending=False).reset_index()
countries_1900_2000_df

"""From this dataframe, we can see that Finland is the country that had the greatest increase in temperature from 1900 to 2000."""

countries_1900_2000_df.boxplot(column=['AvgTempIn1900', 'AvgTempIn2000'], grid=True)
plt.title('Countries Average Temperature 1900 vs 2000')

"""From this, we are able to see how the overall temperatures rose for the countries in just a century, from 1900 to 2000."""

import scipy as sp

countries_change_df = countries_yearly_df[(countries_yearly_df['Year'] >= 1900) & (countries_yearly_df['Year'] <= 2000)][['Country', 'Year', 'AverageTemperature']]
countries_change_df = countries_change_df.sort_values('Year', ascending=True)
finland_change_df = countries_change_df[countries_change_df['Country'] == 'Finland']

sns.set(rc = {'figure.figsize':(15,10)})
countries_change_graph = sns.regplot(x = 'Year', y = 'AverageTemperature', data = st_petersburg_change_df)
countries_change_graph.set( xlabel = "Year", ylabel = "Average Temperature")
countries_change_graph.set(title="Average Temperature of Finland from 1900 to 2000")
countries_change_graph

sns.set(rc = {'figure.figsize':(15,10)})
sns.scatterplot(data= countries_1900_2000_df, x="index", y="ChangeInAvgTemp")
plt.title('Change in average temperature for each country from 1900 to 2000')

count_less_countries = countries_1900_2000_df['ChangeInAvgTemp'][countries_1900_2000_df['ChangeInAvgTemp'] < 0.0].count()
count_greater_countries = countries_1900_2000_df['ChangeInAvgTemp'][countries_1900_2000_df['ChangeInAvgTemp'] > 0.0].count()

count_less_countries

count_greater_countries

"""From what we can see here, there are 226 countries that have a change in the average temperature that are above 0 and 11 countries that have a change in the average temperature that are below 0. That is a 95% rate for increasing temperatures overall in the countries from 1900 to 2000.

We then repeated this whole process with our states data set.
"""

states_1900_df = states_yearly_df[states_yearly_df['Year'] == 1900][['State', 'AverageTemperature']]
states_1900_df = states_1900_df.rename(columns={'AverageTemperature' : 'AvgTempIn1900'})

states_2000_df = states_yearly_df[states_yearly_df['Year'] == 2000][['State', 'AverageTemperature']]
states_2000_df = states_2000_df.rename(columns={'AverageTemperature' : 'AvgTempIn2000'})

states_1900_2000_df = pd.merge(states_1900_df, states_2000_df, how="inner", on=['State'])
states_1900_2000_df['ChangeInAvgTemp'] = states_1900_2000_df['AvgTempIn2000'] - states_1900_2000_df['AvgTempIn1900']
states_1900_2000_df = states_1900_2000_df.sort_values('ChangeInAvgTemp', ascending=False).reset_index()
states_1900_2000_df

"""From this dataframe, we can see that Samara is the state with the greatest increase in temperature from 1900 to 2000."""

states_1900_2000_df.boxplot(column=['AvgTempIn1900', 'AvgTempIn2000'], grid=True)
plt.title('States Average Temperature 1900 vs 2000')

"""From this, we are able to see how the overall temperatures rose for the states in just a century, from 1900 to 2000."""

import scipy as sp

states_change_df = states_yearly_df[(states_yearly_df['Year'] >= 1900) & (states_yearly_df['Year'] <= 2000)][['State', 'Year', 'AverageTemperature']]
states_change_df = states_change_df.sort_values('Year', ascending=True)
samara_change_df = states_change_df[states_change_df['State'] == 'Samara']

sns.set(rc = {'figure.figsize':(15,10)})
states_change_graph = sns.regplot(x = 'Year', y = 'AverageTemperature', data = st_petersburg_change_df)
states_change_graph.set( xlabel = "Year", ylabel = "Average Temperature")
states_change_graph.set(title="Average Temperature of Samara from 1900 to 2000")
states_change_graph

sns.set(rc = {'figure.figsize':(15,10)})
sns.scatterplot(data= states_1900_2000_df, x="index", y="ChangeInAvgTemp")
plt.title('Change in average temperature for each state from 1900 to 2000')

count_less_states = states_1900_2000_df['ChangeInAvgTemp'][states_1900_2000_df['ChangeInAvgTemp'] < 0.0].count()
count_greater_states = states_1900_2000_df['ChangeInAvgTemp'][states_1900_2000_df['ChangeInAvgTemp'] > 0.0].count()

count_less_states

count_greater_states

"""From what we can see here, there are 203 states that have a change in the average temperature that are above 0 and 38 states that have a change in the average temperature that are below 0. That is a 84% rate for increasing temperatures overall in the states from 1900 to 2000.

# Section 3: Using Machine Learning to Make Temperature Predictions

In this section, we want to be able to use machine learning to see how temperatures are going to look like in the future and make some predictions. So, we now want to be able to predict the average temperature in 2050. We will do so by training our model in the following ways:

To start, we need to create new dataframes for cities, countries, and states. We need to do this because we want to have them sorted by both year and city.
"""

cities_ML_df = cities_yearly_df.sort_values(['City', 'Year'], ascending=True)
cities_ML_one_df = cities_ML_df[cities_ML_df['City'] == 'Saint Petersburg']
cities_ML_one_df = cities_ML_one_df.set_index('Year')

cities_ML_one_df

countries_ML_df = countries_df.sort_values(['Country', 'Year'], ascending=True)
countries_ML_df = countries_ML_df.groupby(['Country', 'Year']).mean().reset_index()
countries_ML_df = countries_ML_df[countries_ML_df['Country'] == 'China']
countries_ML_df = countries_ML_df.set_index('Year')

countries_ML_df

states_ML_df = states_df.sort_values(['State', 'Year'], ascending=True)
states_ML_df = states_ML_df.groupby(['State', 'Year']).mean().reset_index()
states_ML_df = states_ML_df[states_ML_df['State'] == 'District Of Columbia']
states_ML_df = states_ML_df.set_index('Year')

states_ML_df

"""For all of the following predictions, we used SARIMAX. SARIMAX is seasonal ARIMA which was of a better use that just using ARIMA.

**Predicting temperature change over time for a city, Saint Petersburg**

---

We will start with predicting the temperature change in St. Petersburg for the year 2050.
"""

model = sm.tsa.statespace.SARIMAX(cities_ML_one_df['AverageTemperature'], order=(2, 1, 0), seasonal_order=(1,1,1,12))
results = model.fit()

pred_df = pd.DataFrame(results.predict(end=307))
pred_df.index = np.arange(1743, len(pred_df) + 1743)
pred_df.head()

"""Now, we want to plot this and see what the temperature will look like in 2050."""

plt.plot(pred_df)
plt.title('2050 Predictions for St. Petersburg')
plt.xlabel('Year')
plt.ylabel('Temperature')
plt.axvspan(1975, 2050, color='red', alpha=0.5)
plt.axvspan(1817, 1975, color='green', alpha=0.4)

"""We are able to see a multiude of things from this graph. We mainly are able to see the predicted values for the next 40 years. It is predicted from out graph above to have an average temperature of around 6.5 degree celsius in St. Petersburg in 2050. We denoted the green block of the graqph to show consistency and not too much of a rise in the average temperatures, but then the red block for when the average began to rise increasingly.

**Predicting temperature change over time for a country, China**


---

We will continue by predicting the temperature change in China for the year 2050.
"""

model_countries = sm.tsa.statespace.SARIMAX(countries_ML_df['AverageTemperature'], order=(2, 1, 0), seasonal_order=(1,1,1,12))
results_countries = model_countries.fit()

pred_df_2 = pd.DataFrame(results_countries.predict(end=230))
pred_df_2.index = np.arange(1820, len(pred_df_2) + 1820)
pred_df_2.head()

"""Now, we want to plot this and see what the temperature will look like in 2050."""

plt.plot(pred_df_2)
plt.title('2050 Predictions for China')
plt.xlabel('Year')
plt.ylabel('Temperature')
plt.axvspan(1978, 2050, color='red', alpha=0.5)
plt.axvspan(1898, 1953, color='lightgreen', alpha=0.4)
plt.axvspan(1844, 1898, color='green', alpha=0.4)

"""We are able to see a multiude of things from this graph. We mainly are able to see the predicted values for the next 40 years. It is predicted from out graph above to have an average temperature of around 9.8 degree celsius in China in 2050. We denoted the green block of the graqph to show consistency and not too much of a rise in the average temperatures. The light green block shows moderate rise in temperature overtime. Lastly, the red block denotes the unfortunate of when the average temperature began to rise increasingly.

**Predicting temperature change over time for a state, District of Columbia**


---
"""

model_states = sm.tsa.statespace.SARIMAX(states_ML_df['AverageTemperature'], order=(2, 1, 0), seasonal_order=(1,1,1,12))
results_states = model_states.fit()

pred_df_3 = pd.DataFrame(results.predict(end=307))
pred_df_3.index = np.arange(1743, len(pred_df_3) + 1743)
pred_df_3.head()

"""Now, we want to plot this and see what the temperature will look like in 2050."""

plt.plot(pred_df_3)
plt.title('2050 Predictions for District of Columbia')
plt.xlabel('Year')
plt.ylabel('Temperature')
plt.axvspan(1984, 2050, color='red', alpha=0.5)
plt.axvspan(1840, 1940, color='green', alpha=0.4)

"""We are able to see a multiude of things from this graph. We mainly are able to see the predicted values for the next 40 years. It is predicted from out graph above to have an average temperature of around 6.5 degree celsius in the District of Columbia in 2050. We denoted the green block of the graqph to show consistency and not too much of a rise in the average temperatures. The red block denotes the unfortunate of when the average temperature began to rise increasingly.

**Failed predictions of temperature change over time**

---

We were encouraged to keep the models we tried that did not work out well in the notebook too. So, we had initlaly started with using ARIMA, instead of the seasonal version of ARIMA and we found we were not getting optimal results. So, we switched to seasonal ARIMA. 

We also did not pursue this more as we were using the entire city data, not just pickmign from one city.
"""

cities_df_fail = cities_yearly_df.sort_values(['City', 'Year'], ascending=True)
cities_df_fail = cities_df_fail.groupby(['City']).mean().reset_index()
cities_df_fail = cities_df_fail.set_index('Year')
cities_df_fail

from statsmodels.tsa.arima_model import ARIMA

model = ARIMA(np.asarray(cities_ML_df['AverageTemperature']), order=(1,1,1))
results_cities = model.fit()
results_cities.summary()

pred_cities = pd.DataFrame(results_cities.predict(end=307))
pred_cities.index = np.arange(1743, len(pred_cities) + 1743)
pred_cities.head()

plt.plot(pred_cities)
plt.title('2050 Predictions for Cities')
plt.xlabel('Year')
plt.ylabel('Temperature')

predictions_cities_ARIMA_diff = pd.Series(results_cities.fittedvalues, copy=True)
predictions_cities_ARIMA_diff.head()

predictions_cities_ARIMA_cumsum = predictions_cities_ARIMA_diff.cumsum()
predictions_cities_ARIMA_cumsum.head()

"""## Section 4: Looking at Correlation with Natural Disasters

In this section, we aim to be able to illustrate the connection that exists between the influx of natural disasters and the rising temperatures that we saw above. We focus on a metric defined as 'total_affected_rate_per_100k_all_disasters' because it is the most wholistic representation for natural callamities that can manifest in many different ways. This metric includes the deaths, fiscal losses, homelessness and injuries of:

*   Drought
*   Earthquakes
* Volcanos
* Floods
* Storms, Landslides, etc.
* Wildfires
* Extreme Temperatures
"""

disasters_df = pd.read_csv('natural-disasters.csv')
disasters_parsed_df = disasters_df[["Entity", "Year", "total_affected_rate_per_100k_all_disasters"]]

disasters_parsed_df

"""We can see above that these Entities above are the total disaster rates every ten years for major countries. We want to be able to compare them to the above country datasets to find interesting correlations of natural disasters and rising surface temperatures

---

Want to find the total number of entities (countries) represented - Note that a 'World' count exists
"""

grouped_disasters_df = disasters_parsed_df.groupby(by="Entity").count()
print(len(grouped_disasters_df))
print(grouped_disasters_df)

world_plot_df = disasters_parsed_df[disasters_parsed_df['Entity'] == 'World']
world_plot_df.plot(x ='Year', y='total_affected_rate_per_100k_all_disasters', kind = 'line', legend=True)
plt.xlabel('Year') 
plt.ylabel('Total affected rate per 100k')
plt.title("World Average for natural disasters")
plt.show()

"""We are able to see here from the graph above that there was a huge jump in disasters from around 1950 to 1990. The jump goes from around 50 a year to as many as 3,500 disasters a year on average for the world.

Next, we will look at the data for the top 5 entities that are global polluters:
"""

china_plot_df = disasters_parsed_df[disasters_parsed_df['Entity'] == 'China']
india_plot_df = disasters_parsed_df[disasters_parsed_df['Entity'] == 'India']
unitedstates_plot_df = disasters_parsed_df[disasters_parsed_df['Entity'] == 'United States']
russia_plot_df = disasters_parsed_df[disasters_parsed_df['Entity'] == 'Russia']
japan_plot_df = disasters_parsed_df[disasters_parsed_df['Entity'] == 'Japan']
five_largest_df = china_plot_df.merge(india_plot_df,left_on="Year", right_on="Year", how="outer")
five_largest_df = five_largest_df.rename(columns={'total_affected_rate_per_100k_all_disasters_x': 'total_affected_rate_per_100k_all_disasters_china', 
                                                  'total_affected_rate_per_100k_all_disasters_y': 'total_affected_rate_per_100k_all_disasters_india'})
five_largest_df = five_largest_df.merge(unitedstates_plot_df, on='Year', how="outer")
five_largest_df = five_largest_df.rename(columns={'total_affected_rate_per_100k_all_disasters': 'total_affected_rate_per_100k_all_disasters_unitedstates'})
five_largest_df = five_largest_df.merge(russia_plot_df, on='Year', how="outer")
five_largest_df = five_largest_df.rename(columns={'total_affected_rate_per_100k_all_disasters': 'total_affected_rate_per_100k_all_disasters_russia'})
five_largest_df = five_largest_df.merge(japan_plot_df, on='Year', how="outer")
five_largest_df = five_largest_df.rename(columns={'total_affected_rate_per_100k_all_disasters': 'total_affected_rate_per_100k_all_disasters_japan'})

"""Below is a graph to show the trends for the 5 largest global polluters:"""

plt.plot(five_largest_df['Year'], five_largest_df['total_affected_rate_per_100k_all_disasters_china'], label='China')
plt.plot(five_largest_df['Year'], five_largest_df['total_affected_rate_per_100k_all_disasters_india'], label='India')
plt.plot(five_largest_df['Year'], five_largest_df['total_affected_rate_per_100k_all_disasters_unitedstates'], label='United States')
plt.plot(five_largest_df['Year'], five_largest_df['total_affected_rate_per_100k_all_disasters_russia'], label='Russia')
plt.plot(five_largest_df['Year'], five_largest_df['total_affected_rate_per_100k_all_disasters_japan'], label='Japan')
plt.title('The five largest global polluters')
plt.legend()
plt.show()

"""This graph tells us the top contributers to pollution also had a plethora of natural disasters occur also during this time from around the 1950s to 1990s, showing how global warming has contributed to a rise in natural disasters. Here, they also keep continuing into the 2000s as well, but the main peaks are between the 1950s and 1990s, especially for China and India.

### Now we are going to look at Greenhouse Gasses and use this to include as features in predicting the AverageTemperature of Countries
"""

greenhouse_df = pd.read_csv('greenhouse_gas_inventory_data_data.csv')
greenhouse_df = greenhouse_df.rename(columns={'value': 'tons_gas_outputed'})
greenhouse_df.head()

countries_yearly_df.head()

merged_countries = pd.merge(countries_yearly_df, greenhouse_df, left_on='Country', right_on="country_or_area")

"""The purpose of creating a grouped_countries is to relate the tons_gas_outputed to the other dataframes that we have so that it can later be used as a feature to help predict the GlobalTemperature rises"""

grouped_countries = merged_countries[['Country', 'AverageTemperature', 'tons_gas_outputed']].groupby("Country").mean()

average_year_disasters_df = disasters_df.groupby(["Entity"]).mean().reset_index()
features_df = pd.merge(average_year_disasters_df, grouped_countries, left_on="Entity", right_on="Country", how="inner")

"""The following features that are used in order to predict the temperature are all used for specific purposes:

*   Number of deaths from drought
** Wanted to have drought representation as it is typically correlated with dry and hot temperatures. Further, have tested using different statistics that relate to droughts and wanted to include a feature that has to do with deaths to test if deaths are a correlated featue (which we have shown below is)
*   Total economic damages from storms as a share of GDP
** Storms are also a factor that relates to temperatures. The reason for looking at GDP strain is to see how much this factor correlates with higher Temperatures, to demonstrate an economic incentive to act to prevent these upwards facing trends
* Total economic damages from volcanic activity as a share of GDP
** Similar rationale to above, but through looking at volcanos to simply test the relationship of more types of natural disasters with the rising temperatures
* injured_rate_per_100k_storm
** Used to diversify the catagories of disaster that are being used as features
* total_affected_rate_per_100k_all_disasters
** This is the most overarching of all of the features and is used to show the different types of natural disasters all cumulated into one statistic
* tons_gas_outputed
** This feature is different from all those above and is meant to connect a countries pollution to the rises of temperatures
"""

features_df = features_df[['Number of deaths from drought','Total economic damages from storms as a share of GDP', 
                           'Total economic damages from volcanic activity as a share of GDP.1', 'deaths_rate_per_100k_storm',
                           'injured_rate_per_100k_storm', 'total_affected_rate_per_100k_all_disasters', 'tons_gas_outputed',
                           'Entity', 'AverageTemperature']]

features = features_df.drop(columns=['Entity', 'AverageTemperature'])
#Creating the Temperature Prediction
temperature = features_df['AverageTemperature']

"""Split the data into testing and training:"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(features, temperature, test_size=0.8, random_state=42)

from sklearn.linear_model import LinearRegression
x = LinearRegression().fit(x_train, y_train)
y_pred = x.predict(x_test)
score = abs(x.score(x_test, y_test))
print(score)

"""Using the features outlined above we were able to come up with a linear regression model that fits with an R^2 score of 0.807.
This demonstrates that factors that were outlined, various natural disaster information and pollution levels, have an incredibly high relationship with the AverageTemperature of the country.

# Conclusion

Let us summarize some of the most important results:
*   Our predictions indicate that without changes to the current trends we will reach the levels of risen temperature that the UN Climate Report deemed 'too far to come back from' within the next two decades.
*   Over time, there is generally a correlation that includes an increase in pollution in the ability to predict a Country (and world's) rise in Global Temperature. We originally attemped to split this up country by country in terms of pollution, but were not able to create a strong correlation because countries that border each other and have very different policies would still see similar trends purely due to regional proximity. 
*   There is a strong correlation among countries that are experiencing a rise of natural disasters and countries that are the top pollutants.
*   Last, but definitely not least, we can see that the vast majority of countries, states, and cities all have increasing temperatures and have an average temperature that has only increased thus far. The *lowest* rate of increase this far has been the states at an 84% rate for increasing temperatures overall from 1900 to 2000. This is not a low percentage and was only over a century. 


In conclusion, we have confirmed with data many of the fears behind climate change at its current rate. What this data, and no data from the past, can tell you is exactly what will happen in the distant future where technological innovation and international efforts may be able to hinder the rates that we have predicted. So to end this notebook we advise the reader to look into the ways that they can slow the compounding rates in which we see today. Thank you!
"""